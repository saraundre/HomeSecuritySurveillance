{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e09b205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1655349586.png has been sent.human\n",
      "1655349590.png has been sent.human\n",
      "1655349593.png has been sent.human\n",
      "1655349597.png has been sent.human\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression \n",
    "import telepot\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "\n",
    "token = '5477504802:AAHFxyA2ZmVERFwex__eAXhESlJSY7uuxWg' # telegram token\n",
    "receiver_id = 5031347294 # https://api.telegram.org/bot <TOKEN>/getUpdates\n",
    "bot = telepot.Bot(token)\n",
    "bot.sendMessage(receiver_id, 'Your camera is active now. ') # send a message on telegram\n",
    "\n",
    "camera = 0 # webcam\n",
    "path = 'D:/scut/scut year +scholarship app/year 3 sem 2/software engineer/hss/yolov5-master/' #path to yolov5\n",
    "weights = f'{path}best.pt' #path to 'model.pt'\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = attempt_load(weights, device=device) # load FP32 model\n",
    "stride = int(model.stride.max()) # model stride\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Capture with opencv and detect object\n",
    "cap = cv2.VideoCapture(camera)\n",
    "width, height = (640 , 480) #quality\n",
    "cap.set(3, width) #width\n",
    "cap.set(4, height) #height\n",
    "\n",
    "#define date and time for comparison\n",
    "now = datetime.datetime.now()\n",
    "today_10am = now.replace(hour=10, minute=0, second=0, microsecond=0)\n",
    "today_3pm = now.replace(hour=15, minute=0, second=0, microsecond=0)\n",
    "\n",
    "\n",
    "#open camera, perform inference and check conditions\n",
    "while(cap.isOpened()):\n",
    "    time.sleep(0.2)\n",
    "    ret, frame_ = cap.read()\n",
    "    frame = cv2.resize(frame_, (width, height), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    #display the current time on the stream\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    frame = cv2.putText(frame,str(datetime.datetime.now()),(10,30), font, 1.5,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): #press q to exit the stream \n",
    "        break\n",
    "        \n",
    "    #inference\n",
    "    if ret ==True:\n",
    "        img = torch.from_numpy(frame).float().to(device).permute(2,0,1)\n",
    "        img/=255.0\n",
    "        \n",
    "        if img.ndimension() ==3:\n",
    "            img = img.unsqueeze(0)\n",
    "            \n",
    "        results = model(img, augment=False)[0]                \n",
    "        pred = non_max_suppression(results, 0.10, 0.20, agnostic=True)\n",
    "                    \n",
    "        #loop and pass pred in conditions\n",
    "        for det in pred:\n",
    "            if len(det):\n",
    "                conf_, class_ = det[0][4], int(det[0][5])\n",
    "                \n",
    "                x1 = int(pred[0][0][0].item())\n",
    "                y1 = int(pred[0][0][1].item())\n",
    "                x2 = int(pred[0][0][2].item())\n",
    "                y2 = int(pred[0][0][3].item())\n",
    "                \n",
    "                #fire and smoke\n",
    "                if (class_ ==0 or class_==1) and conf_> 0.10:\n",
    "                    time_stamp = int(time.time())\n",
    "                    fcm_photo = f'{path}/detected/{time_stamp}.png'\n",
    "                    \n",
    "                    bgr = (0, 0, 255) # color of the box\n",
    "                    image = cv2.rectangle(frame,(x1, y1), (x2, y2),bgr, 3) #Plot the boxes\n",
    "                    #add text\n",
    "                    cv2.putText(image, str(model.names[class_]), (x1,y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "                    cv2.imwrite(fcm_photo, image)\n",
    "                    \n",
    "                    bot.sendPhoto(receiver_id, photo=open(fcm_photo, 'rb'))\n",
    "                    bot.sendMessage(receiver_id, 'ATTENTION! \\nFire or Smoke has been detected at '+str(now))\n",
    "                    print(f'{time_stamp}.png has been sent.fire')\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                #person \n",
    "                if (now > today_10am) and (now < today_3pm) and (class_==2) and conf_> 0.10:\n",
    "                        \n",
    "                    time_stamp = int(time.time())\n",
    "                    fcm_photo = f'{path}/detected/{time_stamp}.png'\n",
    "                    \n",
    "                    bgr = (0, 0, 255) # color of the box\n",
    "                    image = cv2.rectangle(frame,(x1, y1), (x2, y2),bgr, 3) #Plot the boxes\n",
    "                    #add text\n",
    "                    cv2.putText(image, str(model.names[class_]) , (x1,y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "                    cv2.imwrite(fcm_photo, image)\n",
    "                    \n",
    "                    \n",
    "                    bot.sendPhoto(receiver_id, photo=open(fcm_photo, 'rb'))\n",
    "                    bot.sendMessage(receiver_id, 'ATTENTION! \\nA person has been detected at '+str(now))\n",
    "                    print(f'{time_stamp}.png has been sent.human')\n",
    "                    time.sleep(1)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95342c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
